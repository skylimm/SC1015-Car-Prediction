{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "Our response variable for our dataset is Price, a continuous variable. Hence, our problem is a regression problem. We will thus consider a few regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variables for feature data and price values\n",
    "X = new_df.drop([\"Price\"], axis=1) # feature data train  (response)\n",
    "y = new_df[\"Price\"].values # price values train (predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Dataset into Train and Test Datasets\n",
    "We will select 80% of our dataset as our train dataset, and the remaining 20% as our test dataset.\n",
    "\n",
    "The **input** will include the following features: <br>\n",
    "Mileage<br>\n",
    "EngineV<br>\n",
    "Registration<br>\n",
    "Year<br>\n",
    "Engine Type_Gas, Engine Type_Petrol, Engine Type_Diesel, Engine Type_Other<br>\n",
    "Brand_Audi, Brand_BMW, Brand_Mercedes-Benz, Brand_Mitsubishi, Brand_Renault, Brand_Toyota<br>\n",
    "Model_Vista, Model_Vito, Model_X1, Model_X3, Model_X5, Model_X5 M, Model_X6, Model_Yaris, Model_Z3, Model_Z4 ...<br>\n",
    "\n",
    "\n",
    "The **output** will be the car Price.\n",
    "\n",
    "We will be using the same inputs and outputs for all the following regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### The Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression is a widely used supervised learning algorithm in machine learning due to its simplicity and interpretability. It is used to predict continuous numerical values based on one or more independent variables or features. Independent variables or features such as the car's mileage, brand, engine version etc can be used to predict car pricings. <br>\n",
    "\n",
    "The goal of a linear regression model is to find a linear relationship between the independent variables and the dependent variable (i.e., car price). The model does this by estimating the values of the coefficients that multiply each independent variable, such that the sum of the product of these coefficients and independent variables, along with an intercept term, results in the predicted value of the dependent variable (i.e., car price). <br>\n",
    "\n",
    "Once the model is trained on a training dataset, it can be used to predict the car prices on unseen data by applying the learned coefficients to the independent variables of the new data. The accuracy of the model's prediction is typically evaluated using metrics such as the mean squared error (MSE) or R-squared. <br>\n",
    "\n",
    "However, it also has some limitations. For example, it assumes that the relationship between the independent variables and the dependent variable is linear, and it can be sensitive to outliers and multicollinearity. Nevertheless, it remains a useful model for predicting car prices and other numerical values in many real-world applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain HyperParameters for the Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the default hyperparameters for the Linear Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'copy_X': True, 'fit_intercept': True, 'n_jobs': None, 'positive': False}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg_model = LinearRegression()\n",
    "linreg_model_params = linreg_model.get_params()\n",
    "linreg_model_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training for  Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear Regression using Train Data\n",
    "linreg = LinearRegression()         # create the linear regression object\n",
    "linreg.fit(X_train, y_train)        # train the linear regression model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = linreg.predict(X_train)\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "def mean_sq_err(actual, predicted):\n",
    "    '''Returns the Mean Squared Error of actual and predicted values'''\n",
    "    return np.mean(np.square(np.array(actual) - np.array(predicted)))\n",
    "\n",
    "mse = mean_sq_err(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearRegression Training Results\n",
    "The LinearRegression model seems to have good fit our training dataset and achieve the following the results on the training dataset:<br>\n",
    "- Explained Variance (R²) \t: 0.8417371648276059 \n",
    "- Mean Squared Error (MSE) \t: 14073180.660390412\n",
    "- Root Mean Squared Error (RMSE) \t: 3751.4238177511234 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodness Fit of Model (Train set)\n",
      "Explained Variance (R²) \t: 0.8417371648276059\n",
      "Mean Squared Error (MSE) \t: 14073180.660390412\n",
      "Root Mean Squared Error (RMSE) \t: 3751.4238177511234\n"
     ]
    }
   ],
   "source": [
    "print(\"Goodness Fit of Model (Train set)\")\n",
    "\n",
    "# Explained Variance (R²)\n",
    "print(\"Explained Variance (R²) \\t:\", linreg.score(X_train, y_train))\n",
    "\n",
    "print(\"Mean Squared Error (MSE) \\t:\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE) \\t:\", np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing for  Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = linreg.predict(X_test)\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "def mean_sq_err(actual, predicted):\n",
    "    '''Returns the Mean Squared Error of actual and predicted values'''\n",
    "    return np.mean(np.square(np.array(actual) - np.array(predicted)))\n",
    "\n",
    "mse = mean_sq_err(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearRegression Testing Results\n",
    "The LinearRegression model doesn't seems to fit our testing dataset and achieve the following the results on the testing dataset:<br>\n",
    "- Explained Variance (R²) \t: -4.24883870973393e+20\n",
    "- Mean Squared Error (MSE) \t: 4.381265430358157e+28\n",
    "- Root Mean Squared Error (RMSE) \t: 209314725481943.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodness Fit of Model (Test set)\n",
      "Explained Variance (R²) \t: -4.24883870973393e+20\n",
      "Mean Squared Error (MSE) \t: 4.381265430358157e+28\n",
      "Root Mean Squared Error (RMSE) \t: 209314725481943.97\n"
     ]
    }
   ],
   "source": [
    "print(\"Goodness Fit of Model (Test set)\")\n",
    "\n",
    "# Explained Variance (R²)\n",
    "print(\"Explained Variance (R²) \\t:\", linreg.score(X_test, y_test))\n",
    "\n",
    "print(\"Mean Squared Error (MSE) \\t:\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE) \\t:\", np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Linear Regression HyperParameters\n",
    "We will be using GridSearchCV that runs through all the different parameters that is fed into the parameter grid and find the optimal set of hyperparameters for Linear Regression model, thereby improving its performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 'copy_x' and 'n_jobs' affects memory usage and computational efficiency respectively and are unlikely to explain why our model fits better.\n",
    "- Setting 'fit_intercept' to True in linear regression models allows for the model to capture the intercept or constant term, which can reduce bias in the model. Setting 'positive' to True can force the coefficients to be positive, which can improve the interpretability of the model. Hence, we can see a better R² and RMSE values (indicative of a better fit) for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'copy_X': [0, 1],\n",
    "                  'fit_intercept': [0, 1],\n",
    "                  'n_jobs' : [-1, 1, 5, 10],\n",
    "                  'positive'    : [0, 1]\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Grid Search \n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " LinearRegression(copy_X=0, fit_intercept=0, n_jobs=-1, positive=1)\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'copy_X': 0, 'fit_intercept': 0, 'n_jobs': -1, 'positive': 1}\n"
     ]
    }
   ],
   "source": [
    "grid_linreg = GridSearchCV(estimator=linreg_model, param_grid = parameters, cv = 2, n_jobs=-1)\n",
    "grid_linreg.fit(X_train, y_train)\n",
    "\n",
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",grid_linreg.best_estimator_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid_linreg.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain Linear Regression model using Tuned HyperParameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysing the hyperparameters returned by GridSearchCV, the best parameters across ALL searched params:\n",
    " {'copy_X': 0, 'fit_intercept': 0, 'n_jobs': -1, 'positive': 1}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression(copy_X=0, fit_intercept=0, n_jobs=1, positive=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression(copy_X=0, fit_intercept=0, n_jobs=1, positive=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression(copy_X=0, fit_intercept=0, n_jobs=1, positive=1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg_tuned = LinearRegression(copy_X=0, fit_intercept=0, n_jobs=1, positive=1)\n",
    "linreg_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearRegression Training results using Tuning HyperParameters\n",
    "Our tuned Linear Regression model managed to achieve the following results on the following dataset:\n",
    "- Explained Variance (R²) \t: 0.832822917797544\n",
    "- Mean Squared Error (MSE) \t: 14865860.816592315\n",
    "- Root Mean Squared Error (RMSE) \t: 3855.627162549864\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodness Fit of Model (Train set)\n",
      "Explained Variance (R²) \t: 0.832822917797544\n",
      "Mean Squared Error (MSE) \t: 14865860.816592315\n",
      "Root Mean Squared Error (RMSE) \t: 3855.627162549864\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = linreg_tuned.predict(X_train)\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "def mean_sq_err(actual, predicted):\n",
    "    '''Returns the Mean Squared Error of actual and predicted values'''\n",
    "    return np.mean(np.square(np.array(actual) - np.array(predicted)))\n",
    "\n",
    "mse = mean_sq_err(y_train, y_train_pred)\n",
    "\n",
    "print(\"Goodness Fit of Model (Train set)\")\n",
    "\n",
    "# Explained Variance (R²)\n",
    "print(\"Explained Variance (R²) \\t:\", linreg_tuned.score(X_train, y_train))\n",
    "print(\"Mean Squared Error (MSE) \\t:\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE) \\t:\", np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearRegression Testing results using Tuning HyperParameters\n",
    "Our tuned Linear Regression model managed to achieve the following results on the following dataset:\n",
    "- Explained Variance (R²) \t: 0.7211749826587799\n",
    "- Mean Squared Error (MSE) \t: 28751536.432706818\n",
    "- Root Mean Squared Error (RMSE) \t: 5362.04591855635"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodness Fit of Model (Test set)\n",
      "Explained Variance (R²) \t: 0.7211749826587799\n",
      "Mean Squared Error (MSE) \t: 28751536.432706818\n",
      "Root Mean Squared Error (RMSE) \t: 5362.04591855635\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = linreg_tuned.predict(X_test)\n",
    "\n",
    "print(\"Goodness Fit of Model (Test set)\")\n",
    "\n",
    "# Explained Variance (R²)\n",
    "print(\"Explained Variance (R²) \\t:\", linreg_tuned.score(X_test, y_test))\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "def mean_sq_err(actual, predicted):\n",
    "    '''Returns the Mean Squared Error of actual and predicted values'''\n",
    "    return np.mean(np.square(np.array(actual) - np.array(predicted)))\n",
    "\n",
    "\n",
    "mse = mean_sq_err(y_test, y_test_pred)\n",
    "\n",
    "print(\"Mean Squared Error (MSE) \\t:\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE) \\t:\", np.sqrt(mse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "The large negative R² value and extreme RMSE value for our Test dataset before HyperTuning is indicative of a poor fit of the model. This suggests that the model is performing worse than a horizontal line, and is overfitting the training data. Overfitting means that the model has learned the training data too well and is unable to generalize to new data.\n",
    "\n",
    "Hypertuning may have reduced the R² value for train data because it could have made the model less complex, reducing the overfitting on the training data. A simpler model may not perform as well on the training data but may generalize better to new data. But it is important to note that the difference in R² values is small (0.01) and have an insignificant impact on the fit of our model for train data. \n",
    "\n",
    "Hypertuning may have increased the R² value for test data because it could have found the optimal hyperparameters that better fit the test data. By fine-tuning the hyperparameters, the model can be adjusted to fit the data more closely, leading to better performance on the test data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
